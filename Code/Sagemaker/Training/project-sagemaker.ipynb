{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03640927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade -q aiobotocore\n",
    "%pip install -q  xgboost==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b0a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATE THE S3 CLIENTOBJECT AND LOCATIONS INSISDE DEFAULT S3 BUCKET\n",
    "#DEFAULT BUCKER HAS NAME: sagemaker-<region>-<account-id>\n",
    "#<READ> DATASET USED FOR TRAINING SORED IN A PUBLIC S3 BUCKET: sagemaker-sample-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "import joblib\n",
    "import xgboost as xgb #CLASSIFIER: XGBOOST\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Set SageMaker and S3 client variables\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "# Set read and write S3 buckets and locations\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fake-review-detect-demo\"\n",
    "\n",
    "read_bucket = \"sagemaker-sample-files\"\n",
    "read_prefix = \"datasets/tabular/amazon_reviews\" \n",
    "\n",
    "train_data_key = f\"{read_prefix}/train.csv\"\n",
    "test_data_key = f\"{read_prefix}/test.csv\"\n",
    "model_key = f\"{write_prefix}/model\"\n",
    "output_key = f\"{write_prefix}/output\"\n",
    "\n",
    "train_data_uri = f\"s3://{read_bucket}/{train_data_key}\"\n",
    "test_data_uri = f\"s3://{read_bucket}/{test_data_key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fc4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN THE XGBOOST MODEL\n",
    "#-> LABEL COLUMN IS TARGET COLUMN\n",
    "#-> HYPERPARAMETER TUNING: OF XGBOOST; METRIC = ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde48e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO BE TUNED?\n",
    "hyperparams = {\n",
    "                \"max_depth\": 3,\n",
    "                \"eta\": 0.2,\n",
    "                \"objective\": \"binary:logistic\",\n",
    "                \"subsample\" : 0.8,\n",
    "                \"colsample_bytree\" : 0.8,\n",
    "                \"min_child_weight\" : 3\n",
    "              }\n",
    "\n",
    "num_boost_round = 100\n",
    "nfold = 3\n",
    "early_stopping_rounds = 10\n",
    "\n",
    "\n",
    "\n",
    "# Set up data input\n",
    "label_col = \"LABEL\" #TARGET COLUMN\n",
    "data = pd.read_csv(train_data_uri)\n",
    "\n",
    "# Read training data and target\n",
    "train_features = data.drop(label_col, axis=1) #ALL EXCEPT LABEL?\n",
    "train_label = pd.DataFrame(data[label_col])\n",
    "dtrain = xgb.DMatrix(train_features, label=train_label)\n",
    "\n",
    "# Cross-validate on training data\n",
    "cv_results = xgb.cv(\n",
    "    params=hyperparams,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    nfold=nfold,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    metrics=[\"auc\"], #METRIC IS AREA UNDER CURVE\n",
    "    seed=10,\n",
    ")\n",
    "\n",
    "\n",
    "metrics_data = {\n",
    "    \"binary_classification_metrics\": {\n",
    "        \"validation:auc\": {\n",
    "            \"value\": cv_results.iloc[-1][\"test-auc-mean\"],\n",
    "            \"standard_deviation\": cv_results.iloc[-1][\"test-auc-std\"]\n",
    "        },\n",
    "        \"train:auc\": {\n",
    "            \"value\": cv_results.iloc[-1][\"train-auc-mean\"],\n",
    "            \"standard_deviation\": cv_results.iloc[-1][\"train-auc-std\"]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "#CROSS VALIDATED AUC SCORES ON TRAINING AND TESTING DATA\n",
    "#-> DIFFERENCE BETWEEN TWO; POSSIBLE OVERFITTING ON TRAINING DATA\n",
    "print(f\"Cross-validated train-auc:{cv_results.iloc[-1]['train-auc-mean']:.2f}\")\n",
    "print(f\"Cross-validated validation-auc:{cv_results.iloc[-1]['test-auc-mean']:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a93a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(test_data_uri)\n",
    "test_features = data.drop(label_col, axis=1)\n",
    "test_label = pd.DataFrame(data[label_col])\n",
    "dtest = xgb.DMatrix(test_features, label=test_label)\n",
    "\n",
    "model = (xgb.train(params=hyperparams, dtrain=dtrain, evals = [(dtrain,'train'), (dtest,'eval')], num_boost_round=num_boost_round, \n",
    "                  early_stopping_rounds=early_stopping_rounds, verbose_eval = 0)\n",
    "        )\n",
    "\n",
    "# Test model performance on train and test sets\n",
    "test_pred = model.predict(dtest)\n",
    "train_pred = model.predict(dtrain)\n",
    "\n",
    "test_auc = roc_auc_score(test_label, test_pred)\n",
    "train_auc = roc_auc_score(train_label, train_pred)\n",
    "\n",
    "print(f\"Train-auc:{train_auc:.2f}, Test-auc:{test_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a1fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE EVALUATION METRICS AS A JSON FILE\n",
    "#SAVE THE TRAINED MODEL AS A PICKLE FILE\n",
    "#-> BOTH TO LOCAL DIRECTORY WITHING SAGEMAKER STUDIE & DEFAULT S3 BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and performance metrics locally\n",
    "\n",
    "with open(\"./metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics_data, f)\n",
    "\n",
    "with open(\"./xgboost-model\", \"wb\") as f:\n",
    "    joblib.dump(model, f)    \n",
    "    \n",
    "# Upload model and performance metrics to S3\n",
    "\n",
    "metrics_location = output_key + \"/metrics.json\"\n",
    "model_location = model_key + \"/xgboost-model\"\n",
    "\n",
    "s3_client.upload_file(Filename=\"./metrics.json\", Bucket=write_bucket, Key=metrics_location)\n",
    "s3_client.upload_file(Filename=\"./xgboost-model\", Bucket=write_bucket, Key=model_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba216c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda3c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e2376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
