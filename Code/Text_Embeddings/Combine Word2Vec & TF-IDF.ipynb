{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ff5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOAL - COMBINE WORD2VEC & TF-IDF FOR VECTORISATION OF TEXT\n",
    "#AND APPLY STANDARD SCALING ON FINAL VECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a02b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79001d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72622348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE FILE\n",
    "df = pd.read_csv(\"Datasets/amazon_reviews_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8130211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE AND LABEL\n",
    "X = df['PREPROCESSED_REVIEW_TEXT']\n",
    "Y = df['LABEL_ENCODED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4537861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR COMBINING WORD2VEC AND TFIDF\n",
    "\n",
    "def vectorize_text(text):\n",
    "    #TOKENIZE THE TEXT\n",
    "    tokenized_text = [t.split() for t in text]\n",
    "    \n",
    "    #TRAIN THE WORD2VEC MODEL\n",
    "    w2v_model = Word2Vec(sentences=tokenized_text,\n",
    "                        vector_size=100,\n",
    "                         window=5,\n",
    "                         min_count=1\n",
    "                        )\n",
    "    \n",
    "    #W2V VECTORISATION\n",
    "    w2v_vectors = []\n",
    "    \n",
    "    for review in tokenized_text:\n",
    "        review_vectors = [w2v_model.wv[word] for word in review if word in w2v_model.wv]\n",
    "        \n",
    "        #AVERAGE METHOD\n",
    "        if len(review_vectors) > 0:\n",
    "            review_vector = np.mean(review_vectors, axis=0)  # Average the word vectors\n",
    "            w2v_vectors.append(review_vector)\n",
    "            \n",
    "    #VECTORISE USING TF-IDF\n",
    "    vect = TfidfVectorizer()\n",
    "    tfidf_vectors = vect.fit_transform(text).toarray() #SHOULD ONLY RUN ON TRAIN? FIX LATER\n",
    "    \n",
    "    #CONCATENATE\n",
    "    final_vectors = np.concatenate(\n",
    "        (w2v_vectors, tfidf_vectors),\n",
    "        axis = 1 #COMBINE COLUMNS -> HORIZONTAL\n",
    "    )\n",
    "        \n",
    "    return final_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611ac544",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorize_text(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd3da2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN_TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ebf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALE THE VECTORS\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0801f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpandey/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63      2115\n",
      "           1       0.63      0.66      0.64      2085\n",
      "\n",
      "    accuracy                           0.64      4200\n",
      "   macro avg       0.64      0.64      0.64      4200\n",
      "weighted avg       0.64      0.64      0.64      4200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TRAIN 1 MODEL\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#MAKE PREDICTIONS\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9aea0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN AND EVALUATE ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b99b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpandey/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# DICTIONARY WITH NAME AND COMMAND TO INSTANTIATE DIFFERENT MODELS\n",
    "classifiers = {}\n",
    "classifiers.update({\"XGBClassifier\": XGBClassifier(eval_metric='logloss',objective='binary:logistic',use_label_encoder=False)})\n",
    "classifiers.update({\"CatBoostClassifier\": CatBoostClassifier(silent=True)})\n",
    "classifiers.update({\"LinearSVC\": LinearSVC(max_iter=10000)})\n",
    "classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
    "classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
    "classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
    "classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
    "classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
    "classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
    "classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
    "classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
    "classifiers.update({\"BernoulliNB\": BernoulliNB()})\n",
    "classifiers.update({\"LogisticRegression\": LogisticRegression()})\n",
    "classifiers.update({\"SVM\": SVC()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebfde65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18196908,  0.66751683,  0.40509704, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.20301332,  0.360917  ,  0.21874006, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.22365123,  0.92590171,  0.34388262, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.13463682,  0.64746755,  0.32169113, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.1005867 ,  0.56262767,  0.23973559, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.09297816,  0.54184949,  0.32076782, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07849b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME OF MODELS WITH RUN TIME AND AUC SCORES\n",
    "df_models = pd.DataFrame(\n",
    "    columns=['model', 'run_time', 'accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "for key in classifiers:\n",
    "    # STARTING TIME\n",
    "    start_time = time.time()\n",
    "    # CURRENT CLASSIFIER\n",
    "    clf = classifiers[key]\n",
    "    #TRAIN CLASSIFIER ON TRAINING DATA\n",
    "    clf.fit(X_train, y_train)\n",
    "    # MAKE PREDICTIONS USING CURRENT CLASSIFIER\n",
    "    predictions = clf.predict(X_test)\n",
    "    # CALCULATE ACCURACY\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    f1score = f1_score(y_test, predictions)\n",
    "    \n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60, 2)),\n",
    "           'accuracy': accuracy,\n",
    "           'precision': precisaion,\n",
    "           'f1_score': f1score\n",
    "           }\n",
    "\n",
    "    df_models = df_models._append(row, ignore_index=True)\n",
    "\n",
    "df_models = df_models.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f856e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c51f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
