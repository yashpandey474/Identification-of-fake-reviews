{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c566d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOAL - CREATE TEXT EMBEDDINGS OF REVIEW TEXT USING FASTTEXT\n",
    "#INSTEAD OF PREDICTION THROUGH THE FASTTEXT MODEL; USE LOGREG WITH THE EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722dbd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT REQUIRED MODULES\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#IMPORT SUPERVISED CLASSIFIER ALGORITHMS\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd93e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ FILE\n",
    "df = pd.read_csv(\"Datasets/amazon_reviews_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90fffbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURES AND LABELS\n",
    "X = df['PREPROCESSED_REVIEW_TEXT']\n",
    "Y = df['LABEL_ENCODED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24368d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN-TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efa6e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING OF FASTTEXT MODEL\n",
    "fasttext_model = FastText(sentences=X_train, vector_size=100, window=5, min_count=5, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b399b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERT THE TEXT INTO EMBEDDINGS [USING FASTTEXT VECTORS]\n",
    "X_train_embeddings = np.array([np.mean([fasttext_model.wv[word] for word in sentence.split() if word in fasttext_model.wv], axis=0) for sentence in X_train])\n",
    "X_test_embeddings = np.array([np.mean([fasttext_model.wv[word] for word in sentence.split() if word in fasttext_model.wv], axis=0) for sentence in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE - NO SCALING AS EMBEDDINGS OF FASTTEXT ARE ALREADY NORMALISED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40657e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHOOSE MODEL HERE TO COMBINE WITH FASTTEXT [HERE - LOGREG]\n",
    "clf = LogisticRegression()\n",
    "\n",
    "#TRAIN THE MODEL USING TEXT EMBEDDINGS\n",
    "clf.fit(X_train_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0836e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.03138343e-04,  4.06128704e-04, -5.96475729e-05, ...,\n",
       "         1.45523483e-03,  5.99556544e-04, -1.11395156e-03],\n",
       "       [ 5.97906357e-04, -5.77636005e-04, -4.66467063e-05, ...,\n",
       "         1.54219405e-03, -4.74301603e-04,  5.22994414e-05],\n",
       "       [-4.12865513e-04, -6.06556016e-04,  4.58826631e-04, ...,\n",
       "        -3.76118784e-04,  5.84062829e-04, -1.34283720e-04],\n",
       "       ...,\n",
       "       [ 4.16092342e-04,  2.53350154e-04, -6.51807350e-04, ...,\n",
       "         1.73388631e-04, -3.69961344e-04,  1.45691141e-04],\n",
       "       [-4.90103557e-04, -9.03398250e-05,  1.92788386e-04, ...,\n",
       "        -5.61288092e-04, -1.32098823e-04,  5.18169138e-04],\n",
       "       [ 3.14794335e-04, -1.03877916e-03, -5.99701423e-04, ...,\n",
       "        -5.05275966e-04, -1.98538564e-05,  5.12823462e-04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embeddings = X_train_embeddings.astype(float)\n",
    "X_train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c2a290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 53.19047619047619%\n"
     ]
    }
   ],
   "source": [
    "#MAKE PREDICTIONS\n",
    "predictions = clf.predict(X_test_embeddings)\n",
    "\n",
    "\n",
    "#PRINT ACCURACY\n",
    "print(f\"Accuracy = {accuracy_score(y_test, predictions)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51dfb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST WITH ALL TO GET MAXIMUM ACCURACY WITH FASTTEXT\n",
    "# DICTIONARY WITH NAME AND COMMAND TO INSTANTIATE DIFFERENT MODELS\n",
    "classifiers = {}\n",
    "#classifiers.update({\"XGBClassifier\": XGBClassifier(eval_metric='logloss',objective='binary:logistic',use_label_encoder=False)})\n",
    "#classifiers.update({\"CatBoostClassifier\": CatBoostClassifier(silent=True)})\n",
    "#classifiers.update({\"LinearSVC\": LinearSVC(max_iter=10000)})\n",
    "#classifiers.update({\"MultinomialNB\": MultinomialNB()})\n",
    "#classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
    "#classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
    "#classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
    "#classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
    "#classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
    "#classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
    "#classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
    "#classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
    "#classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
    "classifiers.update({\"BernoulliNB\": BernoulliNB()})\n",
    "classifiers.update({\"LogisticRegression\": LogisticRegression()})\n",
    "classifiers.update({\"SVM\": SVC()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33ddf480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME OF MODELS WITH RUN TIME AND AUC SCORES\n",
    "df_models = pd.DataFrame(\n",
    "    columns=['model', 'run_time', 'accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "for key in classifiers:\n",
    "    # STARTING TIME\n",
    "    start_time = time.time()\n",
    "    # CURRENT CLASSIFIER\n",
    "    clf = classifiers[key]\n",
    "    #TRAIN CLASSIFIER ON TRAINING DATA\n",
    "    clf.fit(X_train_embeddings, y_train)\n",
    "    # MAKE PREDICTIONS USING CURRENT CLASSIFIER\n",
    "    predictions = clf.predict(X_test_embeddings)\n",
    "    # CALCULATE ACCURACY\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    f1score = f1_score(y_test, predictions)\n",
    "    \n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60, 2)),\n",
    "           'accuracy': accuracy,\n",
    "           'precision': precision,\n",
    "           'f1_score': f1score\n",
    "           }\n",
    "\n",
    "    df_models = df_models._append(row, ignore_index=True)\n",
    "\n",
    "df_models = df_models.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d31a4066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.534524</td>\n",
       "      <td>0.612457</td>\n",
       "      <td>0.265866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531905</td>\n",
       "      <td>0.594295</td>\n",
       "      <td>0.276141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model run_time  accuracy  precision  f1_score\n",
       "1                 SVM     0.81  0.534524   0.612457  0.265866\n",
       "0  LogisticRegression      0.0  0.531905   0.594295  0.276141"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13aea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
