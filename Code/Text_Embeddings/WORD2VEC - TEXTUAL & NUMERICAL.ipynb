{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c6f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GOAL - IMPLEMENT WORD2VEC FOR VECTORISATION AND STANDARD SCALING FOR NUMERICAL FEATURES\n",
    "#TRAIN THE LIST OF SUPERVISED MODELS ON THIS AND COMPARE WITH TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f674795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc16f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c37545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ THE DATA FILE\n",
    "df = pd.read_csv(\"Datasets/amazon_reviews_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b3b61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'RATING',\n",
       "       'VERIFIED_PURCHASE', 'REVIEW_TITLE', 'REVIEW_TEXT', 'NUM_NOUNS',\n",
       "       'NUM_VERBS', 'NUM_ADJECTIVES', 'NUM_ADVERBS', 'REVIEW_LENGTH',\n",
       "       'SENTIMENT_SCORE', 'TITLE_LENGTH', 'AVERAGE_RATING', 'RATING_DEVIATION',\n",
       "       'NUM_REVIEWS', 'READABILITY_FRE', 'SENTIMENT_CATEGORY_ENCODED',\n",
       "       'RATING_CATEGORY_ENCODED', 'COHERENT_ENCODED', 'AVG_WORD_LENGTH',\n",
       "       'LABEL_ENCODED', 'NUM_NAMED_ENTITIES', 'CAPITAL_CHAR_COUNT',\n",
       "       'PUNCTUATION_COUNT', 'PREPROCESSED_REVIEW_TEXT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23fa550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURES\n",
    "text_features = df['PREPROCESSED_REVIEW_TEXT']\n",
    "numerical_features = df[['REVIEW_LENGTH', 'VERIFIED_PURCHASE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0be6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['LABEL_ENCODED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a445f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    #TOKENIZE THE TEXT\n",
    "    tokenized_text = [text.split() for text in text]\n",
    "\n",
    "    w2v_model = Word2Vec(sentences=tokenized_text, vector_size=100, window=5, min_count=1)\n",
    "    \n",
    "    # CREATE WORD VECTORS\n",
    "    text_vectors = []\n",
    "    for review in tokenized_text:\n",
    "        review_vectors = [w2v_model.wv[word] for word in review if word in w2v_model.wv]\n",
    "        if len(review_vectors) > 0:\n",
    "            review_vector = np.mean(review_vectors, axis=0)  # Example: Average the word vectors\n",
    "            text_vectors.append(review_vector)\n",
    "    \n",
    "    return np.array(text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c32ca3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VECTORISE THE REVIEW TEXTS\n",
    "vectorised_texts = vectorize_text(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9d49d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN-TEST SPLIT FOR THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13db5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
    "     vectorised_texts,\n",
    "     numerical_features,\n",
    "     labels,\n",
    "     test_size = 0.2,\n",
    "     random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee3f6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR THE TF-IDF VECTORISATION\n",
    "X_text_train, X_text_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
    "     text_features,\n",
    "     numerical_features,\n",
    "     labels,\n",
    "     test_size = 0.2,\n",
    "     random_state = 42\n",
    ")\n",
    "\n",
    "vectoriser = TfidfVectorizer()\n",
    "X_text_train = vectoriser.fit_transform(X_text_train)\n",
    "X_text_test = vectoriser.transform(X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acd0b66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16800x29758 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 408765 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SCALE THE NUMERICAL FEATURES\n",
    "X_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb1c2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_num_train = sc.fit_transform(X_num_train)\n",
    "X_num_test = sc.transform(X_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f4fddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE TEXT AND NUMERICAL FEATURES\n",
    "X_train = np.concatenate((X_text_train.toarray(), X_num_train), axis=1)\n",
    "X_test = np.concatenate((X_text_test.toarray(), X_num_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8166b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpandey/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# DICTIONARY WITH NAME AND COMMAND TO INSTANTIATE DIFFERENT MODELS\n",
    "classifiers = {}\n",
    "classifiers.update({\"XGBClassifier\": XGBClassifier(eval_metric='logloss',objective='binary:logistic',use_label_encoder=False)})\n",
    "classifiers.update({\"CatBoostClassifier\": CatBoostClassifier(silent=True)})\n",
    "classifiers.update({\"LinearSVC\": LinearSVC(max_iter=10000)})\n",
    "classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
    "classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
    "classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
    "classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
    "classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
    "classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
    "classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
    "classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
    "classifiers.update({\"BernoulliNB\": BernoulliNB()})\n",
    "classifiers.update({\"LogisticRegression\": LogisticRegression()})\n",
    "classifiers.update({\"SVM\": SVC()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A DATAFRAME OF MODELS WITH RUN TIME AND AUC SCORES\n",
    "df_models = pd.DataFrame(\n",
    "    columns=['model', 'run_time', 'accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "for key in classifiers:\n",
    "    # STARTING TIME\n",
    "    start_time = time.time()\n",
    "    # CURRENT CLASSIFIER\n",
    "    clf = classifiers[key]\n",
    "    #TRAIN CLASSIFIER ON TRAINING DATA\n",
    "    clf.fit(X_train, y_train)\n",
    "    # MAKE PREDICTIONS USING CURRENT CLASSIFIER\n",
    "    predictions = clf.predict(X_test)\n",
    "    # CALCULATE ACCURACY\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    f1score = f1_score(y_test, predictions)\n",
    "    \n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60, 2)),\n",
    "           'accuracy': accuracy,\n",
    "           'precision': precision,\n",
    "           'f1_score': f1score\n",
    "           }\n",
    "\n",
    "    df_models = df_models._append(row, ignore_index=True)\n",
    "\n",
    "df_models = df_models.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ffb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17e8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
