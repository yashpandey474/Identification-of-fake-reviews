{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2871422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "# SENTIMENT ANALYSIS USING VADER\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from gensim.models import Word2Vec\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d64019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/amazon_reviews_labelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c67323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e6dd07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.4', 'Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1',\n",
       "       'Unnamed: 0', 'RATING', 'VERIFIED_PURCHASE', 'REVIEW_TITLE',\n",
       "       'REVIEW_TEXT', 'NUM_NOUNS', 'NUM_VERBS', 'NUM_ADJECTIVES',\n",
       "       'NUM_ADVERBS', 'REVIEW_LENGTH', 'SENTIMENT_SCORE', 'TITLE_LENGTH',\n",
       "       'AVERAGE_RATING', 'RATING_DEVIATION', 'NUM_REVIEWS', 'READABILITY_FRE',\n",
       "       'SENTIMENT_CATEGORY_ENCODED', 'RATING_CATEGORY_ENCODED',\n",
       "       'COHERENT_ENCODED', 'AVG_WORD_LENGTH', 'LABEL_ENCODED',\n",
       "       'NUM_NAMED_ENTITIES', 'CAPITAL_CHAR_COUNT', 'PUNCTUATION_COUNT',\n",
       "       'PREPROCESSED_REVIEW_TEXT', 'WORD_COUNT', 'SENTIMENT_SCORE_TITLE',\n",
       "       'SENTIMENT_LABEL_TITLE', 'AVG_RATING_VERIFIED',\n",
       "       'AVG_RATING_NON_VERIFIED', 'DEVIATION_VERIFIED',\n",
       "       'DEVIATION_NON_VERIFIED'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8634db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_text = df['PREPROCESSED_REVIEW_TEXT']\n",
    "features_numeric = df[[\n",
    "    'RATING', 'VERIFIED_PURCHASE', \n",
    "        'NUM_NOUNS', 'NUM_VERBS', 'NUM_ADJECTIVES',\n",
    "       'NUM_ADVERBS', 'REVIEW_LENGTH', 'SENTIMENT_SCORE', 'TITLE_LENGTH',\n",
    "       'AVERAGE_RATING', 'RATING_DEVIATION', 'NUM_REVIEWS', 'READABILITY_FRE',\n",
    "       'SENTIMENT_CATEGORY_ENCODED', 'RATING_CATEGORY_ENCODED',\n",
    "       'COHERENT_ENCODED', 'AVG_WORD_LENGTH',\n",
    "       'NUM_NAMED_ENTITIES', 'CAPITAL_CHAR_COUNT', 'PUNCTUATION_COUNT',\n",
    "        'WORD_COUNT', 'SENTIMENT_SCORE_TITLE',\n",
    "       'SENTIMENT_LABEL_TITLE', 'AVG_RATING_VERIFIED',\n",
    "       'AVG_RATING_NON_VERIFIED', 'DEVIATION_VERIFIED',\n",
    "       'DEVIATION_NON_VERIFIED'\n",
    "]]\n",
    "labels = df['LABEL_ENCODED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ba7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN-TEST SPLIT\n",
    "X_text_train, X_text_test, X_numeric_train, X_numeric_test, y_train, y_test = train_test_split(\n",
    "    features_text, features_numeric, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f70476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR COMBINING WORD2VEC AND TFIDF\n",
    "\n",
    "def vectorize_text(X_text_train, X_text_test):\n",
    "    #TOKENIZE THE TEXT\n",
    "    tokenized_text_train = [t.split() for t in X_text_train]\n",
    "    tokenized_text_test = [t.split() for t in X_text_test]\n",
    "    \n",
    "    #LOAD PRE-TRAINED WORD2VEC MODEL\n",
    "    model_path = \"word2vec_model.bin\"\n",
    "    if os.path.isfile(model_path):\n",
    "        w2v_model = Word2Vec.load(model_path)\n",
    "    \n",
    "    else:\n",
    "        #TRAIN THE WORD2VEC MODEL\n",
    "        w2v_model = Word2Vec(sentences=tokenized_text_train,vector_size=100,window=5,min_count=1)\n",
    "        #SAVE THE MODEL\n",
    "        w2v_model.save(\"word2vec_model.bin\")\n",
    "        \n",
    "    #W2V VECTORISATION\n",
    "    w2v_vectors_train = []\n",
    "    \n",
    "    for review in tokenized_text_train:\n",
    "        review_vectors = [w2v_model.wv[word] for word in review if word in w2v_model.wv]\n",
    "        \n",
    "        #AVERAGE METHOD\n",
    "        if len(review_vectors) > 0:\n",
    "            review_vector = np.mean(review_vectors, axis=0)  # Average the word vectors\n",
    "            w2v_vectors_train.append(review_vector)\n",
    "            \n",
    "    #W2V VECTORISATION\n",
    "    w2v_vectors_test = []\n",
    "    \n",
    "    for review in tokenized_text_test:\n",
    "        review_vectors = [w2v_model.wv[word] for word in review if word in w2v_model.wv]\n",
    "        \n",
    "        #AVERAGE METHOD\n",
    "        if len(review_vectors) > 0:\n",
    "            review_vector = np.mean(review_vectors, axis=0)  # Average the word vectors\n",
    "            w2v_vectors_test.append(review_vector)\n",
    "    final_vectors_train = w2v_vectors_train\n",
    "    final_vectors_test = w2v_vectors_test\n",
    "        \n",
    "    return final_vectors_train, final_vectors_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc0450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train, X_text_test = vectorize_text(X_text_train, X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc71ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY FEATURE SCALING TO MATRICES\n",
    "sc_numeric = StandardScaler()\n",
    "X_numeric_train = sc_numeric.fit_transform(X_numeric_train)\n",
    "X_numeric_test = sc_numeric.transform(X_numeric_test)\n",
    "\n",
    "sc_text= StandardScaler()\n",
    "X_text_train = sc_text.fit_transform(X_text_train)\n",
    "X_text_test = sc_text.transform(X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124b9578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16800, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9972dd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acb0687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIMENSIONALITY REDUCTION: [NOT NEEDED, ONLY 100 COMPONENTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "068a5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONCATENATE THE TEXTUAL FEATURE AND NUMERIC FEATURE MATRIX\n",
    "X_train = np.hstack((X_text_train, X_numeric_train))\n",
    "X_test = np.hstack((X_text_test, X_numeric_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14edbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARY WITH NAME AND COMMAND TO INSTANTIATE DIFFERENT MODELS\n",
    "classifiers = {}\n",
    "#classifiers.update({\"XGBClassifier\": XGBClassifier(eval_metric='logloss',objective='binary:logistic',use_label_encoder=False)})\n",
    "#classifiers.update({\"CatBoostClassifier\": CatBoostClassifier(silent=True)})\n",
    "#classifiers.update({\"LinearSVC\": LinearSVC(max_iter=10000)})\n",
    "#classifiers.update({\"MultinomialNB\": MultinomialNB()})\n",
    "#classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
    "classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
    "classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
    "classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
    "classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
    "classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
    "classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
    "#classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
    "#classifiers.update({\"BernoulliNB\": BernoulliNB()})\n",
    "classifiers.update({\"LogisticRegression\": LogisticRegression()})\n",
    "classifiers.update({\"SVM\": SVC()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28e2e5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Model Done\n",
      "2th Model Done\n",
      "3th Model Done\n",
      "4th Model Done\n",
      "5th Model Done\n",
      "6th Model Done\n",
      "7th Model Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpandey/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th Model Done\n",
      "9th Model Done\n"
     ]
    }
   ],
   "source": [
    "# CREATE A DATAFRAME OF MODELS WITH RUN TIME AND AUC SCORES\n",
    "df_models = pd.DataFrame(\n",
    "    columns=['model', 'run_time', 'accuracy', 'precision', 'f1_score']\n",
    ")\n",
    "\n",
    "i = 1\n",
    "for key in classifiers:\n",
    "    # STARTING TIME\n",
    "    start_time = time.time()\n",
    "    # CURRENT CLASSIFIER\n",
    "    clf = classifiers[key]\n",
    "    #TRAIN CLASSIFIER ON TRAINING DATA\n",
    "    clf.fit(X_train, y_train)\n",
    "    # MAKE PREDICTIONS USING CURRENT CLASSIFIER\n",
    "    predictions = clf.predict(X_test)\n",
    "    # CALCULATE ACCURACY\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    f1score = f1_score(y_test, predictions)\n",
    "    \n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60, 2)),\n",
    "           'accuracy': accuracy,\n",
    "           'precision': precision,\n",
    "           'f1_score': f1score\n",
    "           }\n",
    "\n",
    "    df_models = df_models._append(row, ignore_index=True)\n",
    "    print(f\"{i}th Model Done\")\n",
    "    i+=1\n",
    "\n",
    "df_models = df_models.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae48b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.816905</td>\n",
       "      <td>0.803786</td>\n",
       "      <td>0.819101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.797229</td>\n",
       "      <td>0.812235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.789806</td>\n",
       "      <td>0.814040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.779298</td>\n",
       "      <td>0.798971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784762</td>\n",
       "      <td>0.759560</td>\n",
       "      <td>0.792661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.781190</td>\n",
       "      <td>0.755926</td>\n",
       "      <td>0.789365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.732381</td>\n",
       "      <td>0.733820</td>\n",
       "      <td>0.728502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.675238</td>\n",
       "      <td>0.679264</td>\n",
       "      <td>0.666992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672143</td>\n",
       "      <td>0.673190</td>\n",
       "      <td>0.666505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model run_time  accuracy  precision  f1_score\n",
       "0  RandomForestClassifier     0.22  0.816905   0.803786  0.819101\n",
       "3      AdaBoostClassifier     0.19  0.810000   0.797229  0.812235\n",
       "8                     SVM     0.69  0.809524   0.789806  0.814040\n",
       "7      LogisticRegression     0.01  0.795238   0.779298  0.798971\n",
       "5         RidgeClassifier      0.0  0.784762   0.759560  0.792661\n",
       "6           SGDClassifier     0.02  0.781190   0.755926  0.789365\n",
       "1  DecisionTreeClassifier     0.05  0.732381   0.733820  0.728502\n",
       "4    KNeighborsClassifier     0.01  0.675238   0.679264  0.666992\n",
       "2     ExtraTreeClassifier      0.0  0.672143   0.673190  0.666505"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbda891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
