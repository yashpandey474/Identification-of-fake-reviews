{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfa7f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "# FRE SCORE\n",
    "from textstat import flesch_reading_ease\n",
    "# SENTIMENT ANALYSIS USING VADER\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#POS TAGGING\n",
    "import spacy\n",
    "#VECTORISING TEXT AND CREATING PIPELINE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "#COSINE SIMILARITY BETWEEN REVIEWS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704bd291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CLASSIFICATION MODULES\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c00e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datasets/Yelp Dataset Reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226fceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56593a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'USER_ID', 'PRODUCT_ID', 'RATING', 'DATE', 'LABEL',\n",
       "       'REVIEW_TEXT', 'AVERAGE_RATING', 'RATING_DEVIATION',\n",
       "       'TOTAL_PRODUCT_REVIEWS', 'REVIEW_LENGTH', 'RATING_CATEGORY',\n",
       "       'SINGLE_RATING_CATEGORY', 'REVIEW_COUNT_DATE',\n",
       "       'SAME_DATE_MULTIPLE_REVIEWS', 'MAX_USER_REVIEWS_DAY',\n",
       "       'TIMESTAMP_DIFFERENCE', 'AVERAGE_USER_REVIEW_LENGTH',\n",
       "       'TOTAL_USER_REVIEWS', 'PERCENTAGE_POSITIVE_REVIEWS',\n",
       "       'RATIO_POSITIVE_NEGATIVE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051ac850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "\n",
      "USER_ID\n",
      "\n",
      "PRODUCT_ID\n",
      "\n",
      "RATING\n",
      "\n",
      "DATE\n",
      "\n",
      "LABEL\n",
      "\n",
      "REVIEW_TEXT\n",
      "\n",
      "AVERAGE_RATING\n",
      "\n",
      "RATING_DEVIATION\n",
      "\n",
      "TOTAL_PRODUCT_REVIEWS\n",
      "\n",
      "REVIEW_LENGTH\n",
      "\n",
      "RATING_CATEGORY\n",
      "\n",
      "SINGLE_RATING_CATEGORY\n",
      "\n",
      "REVIEW_COUNT_DATE\n",
      "\n",
      "SAME_DATE_MULTIPLE_REVIEWS\n",
      "\n",
      "MAX_USER_REVIEWS_DAY\n",
      "\n",
      "TIMESTAMP_DIFFERENCE\n",
      "\n",
      "AVERAGE_USER_REVIEW_LENGTH\n",
      "\n",
      "TOTAL_USER_REVIEWS\n",
      "\n",
      "PERCENTAGE_POSITIVE_REVIEWS\n",
      "\n",
      "RATIO_POSITIVE_NEGATIVE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dac35c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD POS TAGS\n",
    "def add_pos_tags(df):\n",
    "    def count_pos(Pos_counts, pos_type):\n",
    "        pos_count = Pos_counts.get(pos_type, 0)\n",
    "        return pos_count\n",
    "\n",
    "    def pos_counts(text):\n",
    "        doc = nlp(text)\n",
    "        Pos_counts = doc.count_by(spacy.attrs.POS)\n",
    "        return Pos_counts\n",
    "\n",
    "    poscounts = df['REVIEW_TEXT'].apply(pos_counts)\n",
    "    df['NUM_NOUNS'] = poscounts.apply(lambda counts: count_pos(counts, spacy.parts_of_speech.NOUN))\n",
    "    df['NUM_VERBS'] = poscounts.apply(lambda counts: count_pos(counts, spacy.parts_of_speech.VERB))\n",
    "    df['NUM_ADJECTIVES'] = poscounts.apply(lambda counts: count_pos(counts, spacy.parts_of_speech.ADJ))\n",
    "    df['NUM_ADVERBS'] = poscounts.apply(lambda counts: count_pos(counts, spacy.parts_of_speech.ADV))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41769883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD NAMED ENTITIES\n",
    "def add_named_entities(df):\n",
    "    def count_entities(text):\n",
    "        doc = nlp(text)\n",
    "        ent_count = len([ent.text for ent in doc.ents])\n",
    "        return ent_count\n",
    "\n",
    "    df['NUM_NAMED_ENTITIES'] = df['REVIEW_TEXT'].apply(count_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad43b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD SENTIMENT SCORE\n",
    "def add_vader_sentiment_score(df):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    df['SENTIMENT_SCORE'] = df['REVIEW_TEXT'].apply(\n",
    "        lambda d: sid.polarity_scores(d)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e9548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD READABILITY SCORE\n",
    "def add_readability_score(df):\n",
    "    df['READABILITY_FRE'] = df['REVIEW_TEXT'].apply(\n",
    "        lambda d: flesch_reading_ease(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pos_tags(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf5cb5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>RATING</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>REVIEW_TEXT</th>\n",
       "      <th>AVERAGE_RATING</th>\n",
       "      <th>RATING_DEVIATION</th>\n",
       "      <th>TOTAL_PRODUCT_REVIEWS</th>\n",
       "      <th>...</th>\n",
       "      <th>PERCENTAGE_POSITIVE_REVIEWS</th>\n",
       "      <th>RATIO_POSITIVE_NEGATIVE</th>\n",
       "      <th>READABILITY_FRE</th>\n",
       "      <th>NUM_NAMED_ENTITIES</th>\n",
       "      <th>SENTIMENT_SCORE</th>\n",
       "      <th>NUM_NOUNS</th>\n",
       "      <th>NUM_VERBS</th>\n",
       "      <th>NUM_ADJECTIVES</th>\n",
       "      <th>NUM_ADVERBS</th>\n",
       "      <th>PREPROC_REVIEW_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144828</td>\n",
       "      <td>66563</td>\n",
       "      <td>416</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>-1</td>\n",
       "      <td>Great.....</td>\n",
       "      <td>3.767293</td>\n",
       "      <td>0.232707</td>\n",
       "      <td>2183</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.157377</td>\n",
       "      <td>121.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>{95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...</td>\n",
       "      <td>{84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...</td>\n",
       "      <td>{95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...</td>\n",
       "      <td>{87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157607</td>\n",
       "      <td>74755</td>\n",
       "      <td>449</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>1</td>\n",
       "      <td>My family and I had Bubby's brunch on a Saturd...</td>\n",
       "      <td>3.396552</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>812</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.121827</td>\n",
       "      <td>82.65</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>{95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...</td>\n",
       "      <td>{84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...</td>\n",
       "      <td>{95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...</td>\n",
       "      <td>{87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...</td>\n",
       "      <td>family Bubby brunch Saturday morning Â get wai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70401</td>\n",
       "      <td>49165</td>\n",
       "      <td>237</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-10-11</td>\n",
       "      <td>1</td>\n",
       "      <td>I really like this place, but they need to get...</td>\n",
       "      <td>3.799003</td>\n",
       "      <td>0.799003</td>\n",
       "      <td>602</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.082353</td>\n",
       "      <td>67.25</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.7681</td>\n",
       "      <td>{95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...</td>\n",
       "      <td>{84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...</td>\n",
       "      <td>{95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...</td>\n",
       "      <td>{87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...</td>\n",
       "      <td>like place need menu sort finally go brunch ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124810</td>\n",
       "      <td>75653</td>\n",
       "      <td>363</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>This is one of my favorite places in the US. A...</td>\n",
       "      <td>3.990361</td>\n",
       "      <td>1.009639</td>\n",
       "      <td>2075</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.121951</td>\n",
       "      <td>84.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>{95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...</td>\n",
       "      <td>{84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...</td>\n",
       "      <td>{95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...</td>\n",
       "      <td>{87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...</td>\n",
       "      <td>favorite place awesome reservation place pack ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42068</td>\n",
       "      <td>32402</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>1</td>\n",
       "      <td>Make sure you go with a small group of friends...</td>\n",
       "      <td>3.951812</td>\n",
       "      <td>0.048188</td>\n",
       "      <td>2677</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.734545</td>\n",
       "      <td>81.67</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>{95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...</td>\n",
       "      <td>{84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...</td>\n",
       "      <td>{95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...</td>\n",
       "      <td>{87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...</td>\n",
       "      <td>sure small group friend like share food try ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  USER_ID  PRODUCT_ID  RATING        DATE  LABEL  \\\n",
       "0      144828    66563         416       4  2014-12-10     -1   \n",
       "1      157607    74755         449       4  2013-03-26      1   \n",
       "2       70401    49165         237       3  2011-10-11      1   \n",
       "3      124810    75653         363       5  2014-01-14      1   \n",
       "4       42068    32402         100       4  2014-12-02      1   \n",
       "\n",
       "                                         REVIEW_TEXT  AVERAGE_RATING  \\\n",
       "0                                         Great.....        3.767293   \n",
       "1  My family and I had Bubby's brunch on a Saturd...        3.396552   \n",
       "2  I really like this place, but they need to get...        3.799003   \n",
       "3  This is one of my favorite places in the US. A...        3.990361   \n",
       "4  Make sure you go with a small group of friends...        3.951812   \n",
       "\n",
       "   RATING_DEVIATION  TOTAL_PRODUCT_REVIEWS  ...  PERCENTAGE_POSITIVE_REVIEWS  \\\n",
       "0          0.232707                   2183  ...                        100.0   \n",
       "1          0.603448                    812  ...                        100.0   \n",
       "2          0.799003                    602  ...                        100.0   \n",
       "3          1.009639                   2075  ...                        100.0   \n",
       "4          0.048188                   2677  ...                        100.0   \n",
       "\n",
       "   RATIO_POSITIVE_NEGATIVE  READABILITY_FRE  NUM_NAMED_ENTITIES  \\\n",
       "0                 6.157377           121.22                   0   \n",
       "1                 3.121827            82.65                   9   \n",
       "2                 6.082353            67.25                   1   \n",
       "3                 9.121951            84.17                   2   \n",
       "4                 8.734545            81.67                   2   \n",
       "\n",
       "   SENTIMENT_SCORE                                          NUM_NOUNS  \\\n",
       "0           0.0000  {95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...   \n",
       "1           0.9162  {95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...   \n",
       "2          -0.7681  {95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...   \n",
       "3           0.9687  {95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...   \n",
       "4           0.8805  {95: 12, 92: 30, 89: 7, 100: 11, 86: 5, 85: 13...   \n",
       "\n",
       "                                           NUM_VERBS  \\\n",
       "0  {84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...   \n",
       "1  {84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...   \n",
       "2  {84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...   \n",
       "3  {84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...   \n",
       "4  {84: 9, 92: 9, 97: 9, 89: 3, 90: 5, 95: 3, 100...   \n",
       "\n",
       "                                      NUM_ADJECTIVES  \\\n",
       "0  {95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...   \n",
       "1  {95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...   \n",
       "2  {95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...   \n",
       "3  {95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...   \n",
       "4  {95: 12, 100: 11, 93: 2, 92: 18, 86: 12, 89: 3...   \n",
       "\n",
       "                                         NUM_ADVERBS  \\\n",
       "0  {87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...   \n",
       "1  {87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...   \n",
       "2  {87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...   \n",
       "3  {87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...   \n",
       "4  {87: 5, 86: 6, 90: 6, 84: 8, 92: 17, 85: 5, 97...   \n",
       "\n",
       "                                 PREPROC_REVIEW_TEXT  \n",
       "0                                              great  \n",
       "1  family Bubby brunch Saturday morning Â get wai...  \n",
       "2  like place need menu sort finally go brunch ea...  \n",
       "3  favorite place awesome reservation place pack ...  \n",
       "4  sure small group friend like share food try ta...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6c8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_readability_score(df)\n",
    "add_named_entities(df)\n",
    "add_vader_sentiment_score(df)\n",
    "add_pos_tags(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c71331a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESS REVIEW TEXT\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stop_words\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    lemmas = [lemma for lemma in lemmas if lemma.isalpha()]\n",
    "    preprocessed_text = ' '.join(lemmas)\n",
    "\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "484279f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESS THE REVIEW TEXT\n",
    "df['PREPROC_REVIEW_TEXT'] = df['REVIEW_TEXT'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11e08ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERT TIMESTAMP DIFFERENCE TO INTEGER\n",
    "df['TIMESTAMP_DIFFERENCE'] = df['TIMESTAMP_DIFFERENCE'].str.replace(' days', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c6a9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RE-ENCODE LABEL\n",
    "df['LABEL'] = df['LABEL'].apply(lambda x: 0 if x<0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd20101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Datasets/Yelp_Reviews_Labelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b795e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpandey/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# DICTIONARY WITH NAME AND COMMAND TO INSTANTIATE DIFFERENT MODELS\n",
    "classifiers = {}\n",
    "classifiers.update({\"XGBClassifier\": XGBClassifier(eval_metric='logloss',objective='binary:logistic',use_label_encoder=False)})\n",
    "classifiers.update({\"CatBoostClassifier\": CatBoostClassifier(silent=True)})\n",
    "classifiers.update({\"LinearSVC\": LinearSVC(max_iter=10000)})\n",
    "classifiers.update({\"MultinomialNB\": MultinomialNB()})\n",
    "classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
    "classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
    "classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
    "classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
    "classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
    "classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
    "classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
    "classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
    "classifiers.update({\"BernoulliNB\": BernoulliNB()})\n",
    "classifiers.update({\"LogisticRegression\": LogisticRegression()})\n",
    "classifiers.update({\"SVM\": SVC()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4588b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_text = df['PREPROC_REVIEW_TEXT']\n",
    "features_numeric = df[[\n",
    "    'SENTIMENT_SCORE', 'READABILITY_FRE', 'NUM_NAMED_ENTITIES',\n",
    "    'RATING',\n",
    "    'AVERAGE_RATING', 'RATING_DEVIATION',\n",
    "       'TOTAL_PRODUCT_REVIEWS', 'REVIEW_LENGTH', 'RATING_CATEGORY',\n",
    "       'SINGLE_RATING_CATEGORY', 'REVIEW_COUNT_DATE',\n",
    "       'SAME_DATE_MULTIPLE_REVIEWS', 'MAX_USER_REVIEWS_DAY',\n",
    "       'TIMESTAMP_DIFFERENCE', 'AVERAGE_USER_REVIEW_LENGTH',\n",
    "       'TOTAL_USER_REVIEWS', 'PERCENTAGE_POSITIVE_REVIEWS',\n",
    "       'RATIO_POSITIVE_NEGATIVE'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c48a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33c060a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27392d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5438f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN-TEST SPLIT\n",
    "X_text_train, X_text_test, X_numeric_train, X_numeric_test, y_train, y_test = train_test_split(\n",
    "    features_text, features_numeric, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# VEFCTORISE THE TEXTUAL FEATURES\n",
    "tfidf = TfidfVectorizer()\n",
    "X_text_train_tfidf = tfidf.fit_transform(X_text_train)\n",
    "X_text_test_tfidf = tfidf.transform(X_text_test)\n",
    "\n",
    "# Standardize the numeric features\n",
    "# scaler = StandardScaler()\n",
    "# X_numeric_train = scaler.fit_transform(X_numeric_train)\n",
    "# X_numeric_test = scaler.transform(X_numeric_test)\n",
    "\n",
    "# Concatenate the TF-IDF matrix and numeric features\n",
    "X_train = np.hstack((X_text_train_tfidf.toarray(), X_numeric_train))\n",
    "X_test = np.hstack((X_text_test_tfidf.toarray(), X_numeric_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c8477f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Handle missing values\u001b[39;00m\n\u001b[1;32m      2\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# You can choose a different imputation strategy if needed\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m X_test \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Handle infinite values\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/impute/_base.py:390\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    382\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter was deprecated in version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    388\u001b[0m     )\n\u001b[0;32m--> 390\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/impute/_base.py:344\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ve\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_fit:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;66;03m# Use the dtype seen in `fit` for non-`fit` conversion\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_dtype \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/impute/_base.py:327\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    324\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')  # You can choose a different imputation strategy if needed\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Handle infinite values\n",
    "X_train = np.nan_to_num(X_train, nan=0, posinf=1e9, neginf=-1e9)\n",
    "X_test = np.nan_to_num(X_test, nan=0, posinf=1e9, neginf=-1e9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea87412b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA AND TESTING DATA CREATED\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[17:45:07] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/data/data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000014dd4e6d5 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n  [bt] (1) 2   libxgboost.dylib                    0x000000014ddd7440 unsigned long long xgboost::SparsePage::Push<xgboost::data::ArrayAdapterBatch>(xgboost::data::ArrayAdapterBatch const&, float, int) + 1280\n  [bt] (2) 3   libxgboost.dylib                    0x000000014de2481b xgboost::data::SimpleDMatrix::SimpleDMatrix<xgboost::data::ArrayAdapter>(xgboost::data::ArrayAdapter*, float, int) + 299\n  [bt] (3) 4   libxgboost.dylib                    0x000000014ddd5985 xgboost::DMatrix* xgboost::DMatrix::Create<xgboost::data::ArrayAdapter>(xgboost::data::ArrayAdapter*, float, int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 53\n  [bt] (4) 5   libxgboost.dylib                    0x000000014dd60080 XGDMatrixCreateFromDense + 304\n  [bt] (5) 6   libffi.8.dylib                      0x000000010fe84972 ffi_call_unix64 + 82\n  [bt] (6) 7   ???                                 0x00007ff7b04ef8e0 0x0 + 140701791615200\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m clf \u001b[38;5;241m=\u001b[39m classifiers[key]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# TRAIN CLASSIFIER ON TRAINING DATA\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# MAKE PREDICTIONS USING CURRENT CLASSIFIER\u001b[39;00m\n\u001b[1;32m     16\u001b[0m predictions \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1460\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[0;32m-> 1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    429\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    430\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    445\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m    446\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:908\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/data.py:962\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_scipy_csr(\n\u001b[1;32m    959\u001b[0m         data\u001b[38;5;241m.\u001b[39mtocsr(), missing, threads, feature_names, feature_types\n\u001b[1;32m    960\u001b[0m     )\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_array(data):\n\u001b[0;32m--> 962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_numpy_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_uri(data):\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_uri(data, missing, feature_names, feature_types)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/data.py:213\u001b[0m, in \u001b[0;36m_from_numpy_array\u001b[0;34m(data, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    208\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(missing),\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnthread\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(nthread),\n\u001b[1;32m    211\u001b[0m }\n\u001b[1;32m    212\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(args), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 213\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGDMatrixCreateFromDense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_array_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m handle, feature_names, feature_types\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [17:45:07] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/data/data.cc:1104: Check failed: valid: Input data contains `inf` or `nan`\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000014dd4e6d5 dmlc::LogMessageFatal::~LogMessageFatal() + 117\n  [bt] (1) 2   libxgboost.dylib                    0x000000014ddd7440 unsigned long long xgboost::SparsePage::Push<xgboost::data::ArrayAdapterBatch>(xgboost::data::ArrayAdapterBatch const&, float, int) + 1280\n  [bt] (2) 3   libxgboost.dylib                    0x000000014de2481b xgboost::data::SimpleDMatrix::SimpleDMatrix<xgboost::data::ArrayAdapter>(xgboost::data::ArrayAdapter*, float, int) + 299\n  [bt] (3) 4   libxgboost.dylib                    0x000000014ddd5985 xgboost::DMatrix* xgboost::DMatrix::Create<xgboost::data::ArrayAdapter>(xgboost::data::ArrayAdapter*, float, int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 53\n  [bt] (4) 5   libxgboost.dylib                    0x000000014dd60080 XGDMatrixCreateFromDense + 304\n  [bt] (5) 6   libffi.8.dylib                      0x000000010fe84972 ffi_call_unix64 + 82\n  [bt] (6) 7   ???                                 0x00007ff7b04ef8e0 0x0 + 140701791615200\n\n"
     ]
    }
   ],
   "source": [
    "# CREATE A DATAFRAME OF MODELS WITH RUN TIME AND AUC SCORES\n",
    "df_models = pd.DataFrame(\n",
    "    columns=['model', 'run_time', 'accuracy', 'precision', 'f1_score'])\n",
    "\n",
    "print(\"TRAINING DATA AND TESTING DATA CREATED\")\n",
    "i = 1\n",
    "\n",
    "for key in classifiers:\n",
    "    # STARTING TIME\n",
    "    start_time = time.time()\n",
    "    # CURRENT CLASSIFIER\n",
    "    clf = classifiers[key]\n",
    "    # TRAIN CLASSIFIER ON TRAINING DATA\n",
    "    clf.fit(X_train, y_train)\n",
    "    # MAKE PREDICTIONS USING CURRENT CLASSIFIER\n",
    "    predictions = clf.predict(X_test)\n",
    "    # CALCULATE ACCURACY\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    f1score = f1_score(y_test, predictions)\n",
    "\n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60, 2)),\n",
    "           'accuracy': accuracy,\n",
    "           'precision': precision,\n",
    "           'f1_score': f1score\n",
    "           }\n",
    "\n",
    "    df_models = df_models._append(row, ignore_index=True)\n",
    "    print(f\"{i} MODEL DONE\")\n",
    "    i+=1;\n",
    "\n",
    "df_models = df_models.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2da030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
